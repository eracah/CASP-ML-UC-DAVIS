__author__ = 'Evan Racah'

from sklearn import metrics

import pickle
import numpy as np
from HelperFunctions import concatenate_arrays


class TrainingSampleResult(object):
    """Class that acts sort of like a struct for each estimator/training size combo
    It contains any piece of data that might be relevant for plotting or looking at
    It takes in the already-fitted grid_search object for a specific estimator and training size
    (containing the optimal estimator)
    And calculates and stores:
        -the error for each tried parameter
        -the set of all parameters used in optimal estimator (as a dict; key: parameter name, value: parameter value)
        -predicted values for test and train (generated by the predict function on the estimator)
        -actual values for test and train
        -prediction errors (MSE) for test and training data
        -the time to do the grid search for the grid search object
        """
    #TODO: add in more time metrics to this class
    def __init__(self, trials_per_size):
        self.data_dict = {  'best_parameter_values': [],
                            'error_parameter_values': [],
                            'test_predicted_values': [],
                            'test_actual_values': [],
                            'train_predicted_values': [],
                            'train_actual_values': []}
        self.grid_search_objects = []
        self.train_inds = []
        self.train_targets = []
        self.times_to_fit = []
        self.trials = trials_per_size
        self.count = 0


    def add_sample_results(self, grid_search_object, train_inds, train_targets, time_to_fit, data):
        self.grid_search_objects.append(grid_search_object)
        self.train_inds.append(train_inds)
        self.train_targets.append(train_targets)
        self.times_to_fit.append(time_to_fit)
        self.count += 1
        #TODO: This is kinda weird - maybe make this a separate function call
        if self.count == self.trials:
            self._generate_predictions(data)

    def generate_performance_results(self, data, configs):
        train_perf = np.ndarray(len(self.grid_search_objects))
        test_perf = np.ndarray(len(self.grid_search_objects))
        for index, grid in enumerate(self.grid_search_objects):
            # train_targets = self.train_targets[index]
            # test_targets = self.test_targets[index]
            train_predicted = self.data_dict['train_predicted_values'][index]
            train_actual = self.data_dict['train_actual_values'][index]
            test_predicted = self.data_dict['test_predicted_values'][index]
            test_actual = self.data_dict['test_actual_values'][index]
            train_perf[index] = metrics.mean_squared_error(train_predicted,train_actual)
            test_perf[index] = metrics.mean_squared_error(test_predicted,test_actual)
        self.data_dict['train_error'] = train_perf
        self.data_dict['test_error'] = test_perf

    def _generate_predictions(self,data):

        #just pull one trial for best parameter values and error parameter value
        #because hard to average these ones
        self.data_dict['best_parameter_values'].append(self.grid_search_objects[0].best_estimator_.get_params())
        self.data_dict['error_parameter_values'].append(self.grid_search_objects[0].grid_scores_)

        self.data_dict['time_to_fit'] = self.times_to_fit
        #self.data_dict['train_actual_values'] = self.y_trains
        test_data = data.select_targets(data.test_targets)
        x_test = test_data[0]
        y_test = test_data[1]
        self.data_dict['test_predicted_values'] = []
        self.data_dict['test_actual_values'] = []
        self.data_dict['train_predicted_values'] = []
        self.data_dict['train_actual_values'] = []
        for index, grid in enumerate(self.grid_search_objects):
            train_targets = self.train_targets[index]
            train_data = data.select_targets(train_targets)
            x_train = train_data[0]
            y_train = train_data[1]

            self.data_dict['test_predicted_values'].append(grid.best_estimator_.predict(x_test))
            self.data_dict['test_actual_values'].append(y_test)
            self.data_dict['train_predicted_values'].append(grid.best_estimator_.predict(x_train))
            self.data_dict['train_actual_values'].append(y_train)

class EstimatorResult(object):
    """Estimator Results Class:
    Contains a dictionary with a TrainingSampleResult object for each Training Size
    Contains getter methods for a single instance of the TrainingSampleResult class
    Also contains getter methods for getting data from all TrainingSampleResult objects in
    the training sample dict"""

    def __init__(self, estimator_name):
        self.name = estimator_name
        self.training_sample_dict = {}

    def add_training_results(self, training_size, grid_search_object, train_inds, train_targets,
                             time_to_fit, trial,
                             trials_per_size, data):
        if trial == 0:
            self.training_sample_dict[training_size] = TrainingSampleResult(trials_per_size)

        self.training_sample_dict[training_size].add_sample_results(grid_search_object,
                                                                    train_inds,
                                                                    train_targets,
                                                                    time_to_fit,
                                                                    data)


    def get_aggregated_data(self, data_name, sizes):
        means = [obj.data_dict[data_name].mean() for obj in [self.training_sample_dict[size] for size in sizes]]
        vars = [obj.data_dict[data_name].var() for obj in [self.training_sample_dict[size] for size in sizes]]
        return means, vars

    def get_plot_arrays(self, sizes, names):
        ret = len(names)*[0]
        for i, name in enumerate(names):
            if name == 'training_size':
                ret[i] = sizes
            else:
                means, vars = self.get_aggregated_data(name, sizes)
                ret[i] = means
        return ret
    
    def generate_performance_results(self, data, configs):
        for training_sample_results in self.training_sample_dict.itervalues():
           training_sample_results.generate_performance_results(data,configs)

class MainResult(object):
    """Main results class:
    Contains a dictionary, which contains an EstimatorResults object for each estimator
    Also has method for plotting all estimators against each other in a learning curve"""

    def __init__(self, estimator_names, path_to_store_results, file_name):
        """

        :type self: object
        """
        self.estimator_dict = {}
        self.estimator_names = estimator_names

        #add an estimatorResult object for each estimator to the dictionary
        for name in self.estimator_names:
            #make a new key value pair, where key is the estimator and value is an EstimatorResult object
            self.estimator_dict[name] = EstimatorResult(name)

        self.filename = file_name
        self.path = path_to_store_results

    def generate_performance_results(self):
        data = self.data
        for estimator_results in self.estimator_dict.itervalues():
            estimator_results.generate_performance_results(data, self.configs)


    def add_estimator_results(self, estimator_name, training_size, grid_search_object, train_inds,
                              train_targets, time_to_fit, trial, trials_per_size):
        # adds training results to the EstimatorResult object for the corresponding correct estimator_name
        self.estimator_dict[estimator_name].add_training_results(training_size,
                                                                 grid_search_object,
                                                                 train_inds,
                                                                 train_targets,
                                                                 time_to_fit,
                                                                 trial,
                                                                 trials_per_size,
                                                                 self.data)

    #TODO: Move this outside of this class
    def save_data(self):
        with open(self.path + self.filename, 'wb') as f:
            pickle.dump(self, f, pickle.HIGHEST_PROTOCOL)













